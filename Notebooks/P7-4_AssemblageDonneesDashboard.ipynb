{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Implémentation d'un modèle de scoring**\n",
    "## **Notebook 6/6 - Assemblage des données TEST pour le dashboard**\n",
    "*Sofia Chevrolat (Novembre 2020)*\n",
    "___\n",
    "Cette étude vise à réaliser un modèle permettant de prédire le risque de défaut de remboursement d'un prêt pour un client donné. Ce modèle doit être basé sur une variété de données (personnelles, en provenance de différentes sources bancaires, etc.).\n",
    "\n",
    "Ce modèle est destiné à être servi via une API, elle-même appelée via un dashboard interactif. Le modèle devra donc être exporté une fois finalisé.\n",
    "___\n",
    "_**Remerciements**:<br>\n",
    "Merci à mon compagnon [J. Duplan](https://www.linkedin.com/in/julian-duplan-64844a41/) pour les discussions intéressantes.<br>\n",
    "Merci également à mon mentor [Samia Drappeau](https://www.linkedin.com/in/samiadrappeau) pour les échanges d'idées, les conseils et les encouragements !_\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook est organisé comme suit:\n",
    "\n",
    "**0. Mise en place**\n",
    "- 0.1 Chargement des librairies et fonctions utiles\n",
    "- 0.2 Chargement et description du jeu de données\n",
    "- 0.3 Assemblage du jeux de données\n",
    "    \n",
    "**1. Nettoyage**\n",
    "- 1.1 Correction orthographique et typologiques\n",
    "- 1.2 Suppression des outliers\n",
    "    * 1.2.1 Suppression des produits dont le poids indiqué est <= 0\n",
    "    * 1.2.2 Suppression des erreurs de workflow\n",
    "- 1.3 Suppression des features les moins renseignées\n",
    "\n",
    "**4. Analyse exploratoire**\n",
    "- 4.1 Grandeurs statistiques\n",
    "    * 4.1.1 Tendance centrale\n",
    "        * 4.1.1.1 Features qualitatives\n",
    "        * 4.1.1.2 Features quantitatives\n",
    "        \n",
    "**5. Export des données**\n",
    "\n",
    "**6. Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### 0. MISE EN PLACE\n",
    "\n",
    "Dans cette première étape, le cadre de travail est mis en place, c'est-à-dire :\n",
    "- Les librairies et packages Python nécessaires sont chargés\n",
    "- Les fonctions utiles sont définies\n",
    "- Le jeu de données est chargé\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 0.1 CHARGEMENT DES LIBRAIRIES ET FONCTIONS UTILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from joblib import load, dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "path.append(\"./Resources/functions\")\n",
    "\n",
    "import helper_functions as hf\n",
    "import graphical_functions as gf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 0.2 CHARGEMENT ET DESCRIPTION DU JEU DE DONNÉES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "app_test = pd.read_csv(\"./Resources/datasets/origin/application_test.csv\")\n",
    "\n",
    "bureau_balance = pd.read_csv(\"./Resources/datasets/origin/bureau_balance.csv\")\n",
    "\n",
    "bureau = pd.read_csv(\"./Resources/datasets/origin/bureau.csv\")\n",
    "\n",
    "card = pd.read_csv(\"./Resources/datasets/origin/credit_card_balance.csv\")\n",
    "\n",
    "installments = pd.read_csv(\"./Resources/datasets/origin/installments_payments.csv\")\n",
    "\n",
    "cash = pd.read_csv(\"./Resources/datasets/origin/POS_CASH_balance.csv\")\n",
    "\n",
    "prev_app = pd.read_csv(\"./Resources/datasets/origin/previous_application.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### 1. EXPLOITATION DU MODÈLE : PRÉDICTIONS SUR DE NOUVELLES DONNÉEs\n",
    "\n",
    "Afin de démontrer toute la chaîne d'exploitation du modèle, cette partie va utiliser le jeu de données TEST application_test.csv.\n",
    "\n",
    "Ces données n'ayant été utilisées dans aucune des différentes étapes d'élaboration du modèle, elles permettent de montrer l'utilisation du modèle avec de nouvelles données."
   ]
  },
  {
   "source": [
    "___\n",
    "#### 1.1 CHARGEMENT DU MODÈLE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load('../lgbm_trained_model_whole_dataset.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Memory Usage: 0.23 gb.\n",
      "New Memory Usage: 0.1 gb.\n",
      "Original Memory Usage: 0.66 gb.\n",
      "New Memory Usage: 0.25 gb.\n",
      "There are 0 columns with greater than 90% missing values.\n",
      "Original Memory Usage: 0.49 gb.\n",
      "New Memory Usage: 0.16 gb.\n",
      "There are 6 columns with greater than 90% missing values.\n",
      "Original Memory Usage: 0.64 gb.\n",
      "New Memory Usage: 0.29 gb.\n",
      "There are 0 columns with greater than 90% missing values.\n",
      "Original Memory Usage: 0.71 gb.\n",
      "New Memory Usage: 0.34 gb.\n",
      "There are 0 columns with greater than 90% missing values.\n",
      "Original Memory Usage: 0.87 gb.\n",
      "New Memory Usage: 0.44 gb.\n",
      "There are 0 columns with greater than 90% missing values.\n"
     ]
    }
   ],
   "source": [
    "model_ready_df = hf.transform_data(app_test, \n",
    "                                   bureau,                                   \n",
    "                                   bureau_balance,\n",
    "                                   card, \n",
    "                                   cash, \n",
    "                                   installments,\n",
    "                                   prev_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the test data\n",
    "credit_score_predictions = model.predict_proba(model_ready_df)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(data=credit_score_predictions*100)\\\n",
    "                   .rename(columns={0:\"Credit Score\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.concat([app_test[\"SK_ID_CURR\"], predictions_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data for visualization in the dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv(\"./Resources/datasets/assembled/dashboard/predictions_test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}