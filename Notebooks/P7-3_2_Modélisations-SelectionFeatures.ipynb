{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Implémentation d'un modèle de scoring**\n",
    "## **Notebook 4/6 - Modélisation : Sélection des features**\n",
    "*Sofia Chevrolat (Novembre 2020)*\n",
    "___\n",
    "Cette étude vise à réaliser un modèle permettant de prédire le risque de défaut de remboursement d'un prêt pour un client donné. Ce modèle doit être basé sur une variété de données (personnelles, en provenance de différentes sources bancaires, etc.).\n",
    "\n",
    "Ce modèle est destiné à être servi via une API, elle-même appelée via un dashboard interactif. Le modèle devra donc être exporté une fois finalisé.\n",
    "___\n",
    "_**Remerciements**:<br>\n",
    "Merci à mon compagnon [J. Duplan](https://www.linkedin.com/in/julian-duplan-64844a41/) pour les discussions intéressantes.<br>\n",
    "Merci également à mon mentor [Samia Drappeau](https://www.linkedin.com/in/samiadrappeau) pour les échanges d'idées, les conseils et les encouragements !_\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook est organisé comme suit:\n",
    "\n",
    "**0. Mise en place**\n",
    "- 0.1 Chargement des librairies et fonctions utiles\n",
    "- 0.2 Chargement et description du jeu de données\n",
    "- 0.3 Suppression des features non pertinentes\n",
    "- 0.4 Séparation des données\n",
    "    \n",
    "**1. Sélection des features**\n",
    "- 1.1 Baseline : aucune sélection\n",
    "- 1.2 Suppression des features colinéaires\n",
    "- 1.3 Suppression des features présentant plus de 75% de valeurs manquantes\n",
    "- 1.4 Suppression des features ayant une importance nulle pour le modèle\n",
    "- 1.5 Suppression des features ayant une importance inférieure à 95% pour le modèle\n",
    "- 1.6 Comparaison des performances\n",
    "\n",
    "**2. Conclusion**\n",
    "\n",
    "**3. Export des données**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### 0. MISE EN PLACE\n",
    "\n",
    "Dans cette première étape, le cadre de travail est mis en place, c'est-à-dire :\n",
    "- Les librairies et packages Python nécessaires sont chargés\n",
    "- Les fonctions utiles sont définies\n",
    "- Le jeu de données est chargé\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 0.1 CHARGEMENT DES LIBRAIRIES ET FONCTIONS UTILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import time\n",
    "import random\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer\n",
    "import lightgbm as lgb\n",
    "from joblib import load, dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "path.append(\"./Resources/functions\")\n",
    "\n",
    "import helper_functions as hf\n",
    "import graphical_functions as gf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 0.2 CHARGEMENT DES DONNÉES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Resources/datasets/assembled/full_training_data.csv\").rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 0.3 SUPPRESSION DES FEATURES NON PERTINENTES\n",
    "\n",
    "Nous allons supprimer la colonne indiquant l'ID du client.\n",
    "\n",
    "De plus, afin d'éviter de perpétuer des biais, nous allons supprimer la colonne ayant trait au sexe des clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\"SK_ID_CURR\", \"CODE_GENDER_M\", \"CODE_GENDER_F\", \"CODE_GENDER_XNA\"]\n",
    "data_model = data.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 0.4 SÉPARATION DES DONNÉES\n",
    "\n",
    "Le jeu de données va être séparé entre données d'entraînement et données de test.\n",
    "\n",
    "L'analyse exploratoire ayant fait ressortir un important déséquilibre des classes dans TARGET, nous devons veiller à maintenir ces proportions dans nos nouveaux jeux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_model.drop(columns=[\"TARGET\"]), \n",
    "                                                    data_model[\"TARGET\"], \n",
    "                                                    train_size=0.8, random_state=42, \n",
    "                                                    stratify=data_model[\"TARGET\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### 1. SÉLECTION DES FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_score = make_scorer(hf.bank_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=[\"Features\", \"Custom Score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 1.1 BASELINE : AUCUNE SÉLECTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = lgb.LGBMClassifier(n_estimators=10000, \n",
    "                                    objective = 'binary', \n",
    "                                    class_weight = 'balanced', \n",
    "                                    learning_rate = 0.05, \n",
    "                                    reg_alpha = 0.1, \n",
    "                                    reg_lambda = 0.1, \n",
    "                                    subsample = 0.8, \n",
    "                                    n_jobs = -1, \n",
    "                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model.fit(X_train, y_train, eval_metric=custom_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = baseline_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[len(results)] = [\"All features\", \n",
    "                             round(hf.bank_score(y_test, y_pred), 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 1.2 SUPPRESSION DES FEATURES COLINÉAIRES\n",
    "\n",
    "Pour chaque paire de features colinéaires à plus de 90% (coefficient de spearman), l'une des 2 features est supprimée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold for removing correlated variables\n",
    "threshold = 0.9\n",
    "\n",
    "# Absolute value correlation matrix\n",
    "corr_matrix = X_train.corr(\"spearman\").abs()\n",
    "corr_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upper triangle of correlations\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "upper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns with correlations above threshold\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "print('There are %d columns to remove.' % (len(to_drop)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nc = X_train.drop(columns = to_drop)\n",
    "X_test_nc = X_test.drop(columns = to_drop)\n",
    "\n",
    "print('Training shape: ', X_train_nc.shape)\n",
    "print('Testing shape: ', X_test_nc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_model = lgb.LGBMClassifier(n_estimators=10000, \n",
    "                              objective = 'binary', \n",
    "                              class_weight = 'balanced', \n",
    "                              learning_rate = 0.05, \n",
    "                              reg_alpha = 0.1, \n",
    "                              reg_lambda = 0.1, \n",
    "                              subsample = 0.8, \n",
    "                              n_jobs = -1, \n",
    "                              random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_model.fit(X_train_nc, \n",
    "          y_train, \n",
    "          eval_metric = custom_score)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = nc_model.predict(X_test_nc)\n",
    "\n",
    "row = [\"Without collinear\", \n",
    "       hf.bank_score(y_test, y_pred)]\n",
    "\n",
    "results.loc[len(results)] = row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 1.3 SUPPRESSION DES FEATURES PRÉSENTANT PLUS DE 75% DE VALEURS MANQUANTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train missing values (in percent)\n",
    "X_train_collinear_missing = (X_train_nc.isnull().sum() / len(X_train_nc)).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_collinear_missing = X_train_collinear_missing.index[X_train_collinear_missing > THRESHOLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_without_collinear_missing = X_train_nc.drop(columns= X_train_collinear_missing)\n",
    "X_test_without_collinear_missing = X_test_nc.drop(columns= X_train_collinear_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncm_model = lgb.LGBMClassifier(n_estimators=10000, \n",
    "                              objective = 'binary', \n",
    "                              class_weight = 'balanced', \n",
    "                              learning_rate = 0.05, \n",
    "                              reg_alpha = 0.1, \n",
    "                              reg_lambda = 0.1, \n",
    "                              subsample = 0.8, \n",
    "                              n_jobs = -1, \n",
    "                              random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncm_model.fit(X_train_without_collinear_missing, \n",
    "          y_train, \n",
    "          eval_metric = custom_score)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = ncm_model.predict(X_test_without_collinear_missing)\n",
    "\n",
    "row = [\"Without collinear and missing\", \n",
    "       hf.bank_score(y_test, y_pred)]\n",
    "\n",
    "results.loc[len(results)] = row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 1.4 SUPPRESSION DES FEATURES AYANT UNE IMPORTANCE NULLE POUR LE MODÈLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X_train_without_collinear_missing\n",
    "test = X_test_without_collinear_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty array to hold feature importances\n",
    "feature_importances = np.zeros(train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncmnof_model = lgb.LGBMClassifier(n_estimators=10000, \n",
    "                              objective = 'binary', \n",
    "                              class_weight = 'balanced', \n",
    "                              learning_rate = 0.05, \n",
    "                              reg_alpha = 0.1, \n",
    "                              reg_lambda = 0.1, \n",
    "                              subsample = 0.8, \n",
    "                              n_jobs = -1, \n",
    "                              random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model twice to avoid overfitting\n",
    "for i in range(2):\n",
    "    \n",
    "    # Train using early stopping\n",
    "    ncmnof_model.fit(train, \n",
    "              y_train, \n",
    "              eval_metric = custom_score)\n",
    "    \n",
    "    # Record the feature importances\n",
    "    feature_importances += ncmnof_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average feature importances\n",
    "feature_importances = feature_importances / 2\n",
    "feature_importances = pd.DataFrame({'feature': list(train.columns), \n",
    "                                    'importance': feature_importances}).sort_values('importance', ascending = False)\n",
    "\n",
    "feature_importances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the features with zero importance\n",
    "zero_features = list(feature_importances[feature_importances['importance'] == 0.0]['feature'])\n",
    "print('There are %d features with 0.0 importance' % len(zero_features))\n",
    "feature_importances.tail(len(zero_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_feature_importances = gf.plot_feature_importances2(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns = zero_features)\n",
    "test = test.drop(columns = zero_features)\n",
    "\n",
    "print('Training shape: ', train.shape)\n",
    "print('Testing shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_round_zero_features, feature_importances = hf.identify_zero_importance_features(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_feature_importances = gf.plot_feature_importances2(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=second_round_zero_features)\n",
    "test = test.drop(columns=second_round_zero_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training shape: ', train.shape)\n",
    "print('Testing shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_round_zero_features, feature_importances = hf.identify_zero_importance_features(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_feature_importances = gf.plot_feature_importances2(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncmnof_model.fit(train, \n",
    "          y_train, \n",
    "          eval_metric = custom_score)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = ncmnof_model.predict(test)\n",
    "\n",
    "row = [\"Without all + 0 importance features\", \n",
    "       hf.bank_score(y_test, y_pred)]\n",
    "\n",
    "results.loc[len(results)] = row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 1.5 SUPPRESSION DES FEATURES AYANT UNE IMPORTANCE INFÉRIEURE À 95% POUR LE MODÈLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold for cumulative importance\n",
    "THRESHOLD = 0.95\n",
    "\n",
    "# Extract the features to keep\n",
    "features_to_keep = list(norm_feature_importances[norm_feature_importances['cumulative_importance'] < THRESHOLD]['feature'])\n",
    "\n",
    "# Create new datasets with smaller features\n",
    "train_small = train[features_to_keep]\n",
    "test_small = test[features_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncmnofif_model = lgb.LGBMClassifier(n_estimators=10000, \n",
    "                              objective = 'binary', \n",
    "                              class_weight = 'balanced', \n",
    "                              learning_rate = 0.05, \n",
    "                              reg_alpha = 0.1, \n",
    "                              reg_lambda = 0.1, \n",
    "                              subsample = 0.8, \n",
    "                              n_jobs = -1, \n",
    "                              random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncmnofif_model.fit(train_small, \n",
    "          y_train, \n",
    "          eval_metric = custom_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = ncmnofif_model.predict(test_small)\n",
    "\n",
    "row = [\"Without 0 importance features and small\", \n",
    "       hf.bank_score(y_test, y_pred)]\n",
    "\n",
    "results.loc[len(results)] = row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 1.6 COMPARAISON DES PERFORMANCES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le meilleur score est obtenu en supprimant :\n",
    "-   les features colinéaires\n",
    "-   les features avec plus de 75% de valeurs manquantes\n",
    "-   les features ayant 0 importance pour le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = ncmnof_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### 2.CONCLUSION\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À ce stade, notre modèle possède les caractéristiques suivantes : \n",
    "- algorithme : Light Gradient Boosting Machine\n",
    "- stratégie de rééquilibrage : class_weight = 'balanced'\n",
    "- features : sélectionnée dans ce notebook\n",
    "\n",
    "Notre modèle obtient un score de 0.109, soit 10.9% de mieux que la baseline consistant à prédire systématiquement que le client remboursera son crédit.\n",
    "\n",
    "Afin de finaliser notre modèle et d'en améliorer les performances, la dernière étape consiste à optimiser les hyperparamètres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### 3. EXPORT DES DONNÉES\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the best model and the dataset to save time\n",
    "dump(best_model, \"lgbm_best_features_model.joblib\")\n",
    "train.to_csv(\"./Resources/datasets/assembled/train.csv\")\n",
    "y_train.to_csv(\"./Resources/datasets/assembled/y_train.csv\")\n",
    "test.to_csv(\"./Resources/datasets/assembled/test.csv\") \n",
    "y_test.to_csv(\"./Resources/datasets/assembled/y_test.csv\")\n",
    "\n",
    "# Saving columns for new data pipeline\n",
    "dump(train.columns, \"model_features.joblib\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
