{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Implémentation d'un modèle de scoring**\n",
    "## **Notebook 2/6 - Création de features & Assemblage des données**\n",
    "*Sofia Chevrolat (Novembre 2020)*\n",
    "___\n",
    "Cette étude vise à réaliser un modèle permettant de prédire le risque de défaut de remboursement d'un prêt pour un client donné. Ce modèle doit être basé sur une variété de données (personnelles, en provenance de différentes sources bancaires, etc.).\n",
    "\n",
    "Ce modèle est destiné à être servi via une API, elle-même appelée via un dashboard interactif. Le modèle devra donc être exporté une fois finalisé.\n",
    "___\n",
    "_**Remerciements**:<br>\n",
    "Merci à mon compagnon [J. Duplan](https://www.linkedin.com/in/julian-duplan-64844a41/) pour les discussions intéressantes.<br>\n",
    "Merci également à mon mentor [Samia Drappeau](https://www.linkedin.com/in/samiadrappeau) pour les échanges d'idées, les conseils et les encouragements !_\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook est organisé comme suit:\n",
    "\n",
    "**0. Mise en place**\n",
    "- 0.1 Chargement des librairies et fonctions utiles\n",
    "- 0.2 Chargement et description du jeu de données\n",
    "    \n",
    "**1. Création de features & Assemblage des données**\n",
    "- 1.1 Données APP_TRAIN\n",
    "- 1.2 Données BUREAU\n",
    "- 1.3 Données BUREAU_BALANCE\n",
    "- 1.4 Données PREVIOUS APPLICATION\n",
    "- 1.5 Données CASH\n",
    "- 1.6 Données CARTE DE CRÉDIT\n",
    "- 1.7 Données PAIEMENT\n",
    "\n",
    "**2. Traitement des anomalies**\n",
    "        \n",
    "**3. Encodage des données**\n",
    "\n",
    "**4. Export des données**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### 0. MISE EN PLACE\n",
    "\n",
    "Dans cette première étape, le cadre de travail est mis en place, c'est-à-dire :\n",
    "- Les librairies et packages Python nécessaires sont chargés\n",
    "- Les fonctions utiles sont définies\n",
    "- Le jeu de données est chargé\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 0.1 CHARGEMENT DES LIBRAIRIES ET FONCTIONS UTILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "path.append(\"./Resources/functions\")\n",
    "\n",
    "import helper_functions as hf\n",
    "import graphical_functions as gf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 0.2 CHARGEMENT ET DESCRIPTION DU JEU DE DONNÉES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "app_train = pd.read_csv(\"./Resources/datasets/origin/application_train.csv\")\n",
    "\n",
    "bureau_balance = pd.read_csv(\"./Resources/datasets/origin/bureau_balance.csv\")\n",
    "\n",
    "bureau = pd.read_csv(\"./Resources/datasets/origin/bureau.csv\")\n",
    "\n",
    "credit = pd.read_csv(\"./Resources/datasets/origin/credit_card_balance.csv\")\n",
    "\n",
    "installments = pd.read_csv(\"./Resources/datasets/origin/installments_payments.csv\")\n",
    "\n",
    "cash = pd.read_csv(\"./Resources/datasets/origin/POS_CASH_balance.csv\")\n",
    "\n",
    "prev_app = pd.read_csv(\"./Resources/datasets/origin/previous_application.csv\")"
   ]
  },
  {
   "source": [
    "___\n",
    "### 1. CRÉATION DE FEATURES & ASSEMBLAGE DES DONNÉES\n",
    "___"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "___\n",
    "#### 1.1 DONNÉES APP_TRAIN\n",
    "\n",
    "Création d'une feature métier : \n",
    "-   Le ratio apport initial par rapport au prix du bien\n",
    "-   Le ratio annuity / income \n",
    "-   Le ratio ancienneté emploi / âge"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self financed on goods price ratio (%)\n",
    "app_train[\"SELF_FINANCED_PERCENT\"] = (app_train[\"AMT_GOODS_PRICE\"] - app_train[\"AMT_CREDIT\"])/app_train[\"AMT_GOODS_PRICE\"]*100\n",
    "app_train[\"SELF_FINANCED_PERCENT\"] = app_train[\"SELF_FINANCED_PERCENT\"].map(lambda x: 0 if x<0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANNUITY ON INCOME ratio (%)\n",
    "app_train[\"ANNUITY_ON_INCOME\"] = app_train[\"AMT_ANNUITY\"] / app_train[\"AMT_INCOME_TOTAL\"] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Days employed on age ratio (%)\n",
    "app_train['DAYS_EMPLOYED_PERCENT'] = app_train['DAYS_EMPLOYED'] / app_train['DAYS_BIRTH']"
   ]
  },
  {
   "source": [
    "___\n",
    "#### 1.2 DONNÉES BUREAU\n",
    "\n",
    "Création des features suivantes :\n",
    "-   Nombre de prêts bancaires précédents\n",
    "\n",
    "Création des features suivantes par prêt par client :\n",
    "-   Pour chaque feature qualitative :\n",
    "    - nombre\n",
    "    - moyenne\n",
    "    - somme\n",
    "- Pour chaque feature quantitative : \n",
    "    - nombre\n",
    "    - moyenne\n",
    "    - maximum\n",
    "    - minimum\n",
    "    - somme"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original Memory Usage: 0.23 gb.\nNew Memory Usage: 0.1 gb.\n"
     ]
    }
   ],
   "source": [
    "# Convert types for less memory usage\n",
    "bureau = hf.convert_types(bureau, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation de previous_loan_counts\n",
    "previous_loan_counts = bureau.groupby('SK_ID_CURR', \n",
    "                                      as_index=False)['SK_ID_BUREAU']\\\n",
    "                             .count()\\\n",
    "                             .rename(columns = {'SK_ID_BUREAU':\\\n",
    "                                                'previous_loan_counts'})\n",
    "\n",
    "# Merge de previous_loan_counts dans train on SK_ID_CURR, left\n",
    "app_train = app_train.merge(previous_loan_counts, \n",
    "                            on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# fillna(0) dans train\n",
    "app_train['previous_loan_counts'] = app_train['previous_loan_counts']\\\n",
    "                                    .fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of bureau_counts containing for each possible value \n",
    "# of the qualitative features 2 new feature : count and \n",
    "# normalized count\n",
    "\n",
    "bureau_counts = hf.agg_categorical(bureau, \n",
    "                                     group_var = 'SK_ID_CURR', \n",
    "                                     df_name = 'bureau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of bureau_agg containing for each possible value\n",
    "# of the quantitative features 5 new features : count, max,\n",
    "# mean, min and sum\n",
    " \n",
    "bureau_agg = hf.agg_numeric(bureau.drop(columns = ['SK_ID_BUREAU']), \n",
    "                            group_var = 'SK_ID_CURR', \n",
    "                            df_name = 'bureau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 0 columns with greater than 90% missing values.\n"
     ]
    }
   ],
   "source": [
    "# Insert computed features into training data\n",
    "\n",
    "# Merge bureau_counts dans app_train\n",
    "app_train = app_train.merge(bureau_counts, on=\"SK_ID_CURR\", how=\"left\")\n",
    "\n",
    "# Merge bureau_agg dans app_train\n",
    "app_train = app_train.merge(bureau_agg, on=\"SK_ID_CURR\", how=\"left\")\n",
    "\n",
    "# Suppression des colonnes missing\n",
    "app_train = hf.remove_missing_columns(app_train)"
   ]
  },
  {
   "source": [
    "___\n",
    "#### 1.3 DONNÉES BUREAU_BALANCE\n",
    "\n",
    "Création des features suivantes par prêt par client :\n",
    "-   Pour chaque features qualitative :\n",
    "    - nombre\n",
    "    - moyenne\n",
    "    - somme\n",
    "-   Features mathématiques pour chaque features quantitative par prêt par client : \n",
    "    - nombre\n",
    "    - moyenne\n",
    "    - maximum\n",
    "    - minimum\n",
    "    - somme"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original Memory Usage: 0.66 gb.\nNew Memory Usage: 0.25 gb.\n"
     ]
    }
   ],
   "source": [
    "# Convert types for less memory usage\n",
    "bureau_balance = hf.convert_types(bureau_balance, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comptage des catégories\n",
    "# Counts of each type of status for each previous loan\n",
    "bureau_balance_counts = hf.agg_categorical(bureau_balance, \n",
    "                                           group_var = 'SK_ID_BUREAU', \n",
    "                                           df_name = 'bureau_balance')\n",
    "\n",
    "# Creation de bureau_balance_agg \n",
    "# Calculate value count statistics for each `SK_ID_CURR` \n",
    "bureau_balance_agg = hf.agg_numeric(bureau_balance, \n",
    "                                    group_var = 'SK_ID_BUREAU', \n",
    "                                    df_name = 'bureau_balance')\n",
    "\n",
    "# Creation de bureau_by_loan\n",
    "# Dataframe grouped by the loan\n",
    "bureau_by_loan = bureau_balance_agg.merge(bureau_balance_counts, \n",
    "                                          right_index = True, \n",
    "                                          left_on = 'SK_ID_BUREAU', \n",
    "                                          how = 'outer')\n",
    "\n",
    "# Merge to include the SK_ID_CURR - Possibly several rows per client\n",
    "bureau_by_loan = bureau_by_loan.merge(bureau[['SK_ID_BUREAU', 'SK_ID_CURR']], \n",
    "                                      on = 'SK_ID_BUREAU', \n",
    "                                      how = 'left')\n",
    "\n",
    "# Creation de bureau_balance_by_client - One row per client\n",
    "bureau_balance_by_client = hf.agg_numeric(bureau_by_loan.drop(columns = ['SK_ID_BUREAU']), \n",
    "                                          group_var = 'SK_ID_CURR', \n",
    "                                          df_name = 'client')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 0 columns with greater than 90% missing values.\n"
     ]
    }
   ],
   "source": [
    "# Merge bureau_balance_by_client dans app_train\n",
    "app_train = app_train.merge(bureau_balance_by_client, on=\"SK_ID_CURR\", how=\"left\")\n",
    "\n",
    "# Suppression des colonnes missing\n",
    "app_train = hf.remove_missing_columns(app_train)"
   ]
  },
  {
   "source": [
    "___\n",
    "#### 1.4 DONNÉES PREVIOUS APPLICATION\n",
    "\n",
    "Création des features suivantes :\n",
    "- Features mathématiques pour chaque feature qualitative par client : \n",
    "    - somme\n",
    "    - nombre\n",
    "    - moyenne\n",
    "- Features mathématiques pour chaque features quantitative par client : \n",
    "    - nombre\n",
    "    - moyenne\n",
    "    - maximum\n",
    "    - minimum\n",
    "    - somme"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original Memory Usage: 0.49 gb.\nNew Memory Usage: 0.16 gb.\n"
     ]
    }
   ],
   "source": [
    "# Convert types de previous\n",
    "prev_app = hf.convert_types(prev_app, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation de previous_agg\n",
    "prev_agg = hf.agg_numeric(prev_app, 'SK_ID_CURR', 'previous')\n",
    "\n",
    "# Creation de previous_counts\n",
    "prev_counts = hf.agg_categorical(prev_app, 'SK_ID_CURR', 'previous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 6 columns with greater than 90% missing values.\n"
     ]
    }
   ],
   "source": [
    "# Merge previous_counts dans app_train\n",
    "app_train = app_train.merge(prev_counts, on=\"SK_ID_CURR\", how=\"left\")\n",
    "\n",
    "# Merge previous_agg dans app_train\n",
    "app_train = app_train.merge(prev_agg, on=\"SK_ID_CURR\", how=\"left\")\n",
    "\n",
    "# Suppression des colonnes missing\n",
    "app_train = hf.remove_missing_columns(app_train)"
   ]
  },
  {
   "source": [
    "___\n",
    "#### 1.5 DONNÉES CASH\n",
    "\n",
    "Création des features suivantes :\n",
    "- Features mathématiques pour chaque feature qualitative par client : \n",
    "    - somme\n",
    "    - nombre\n",
    "    - moyenne\n",
    "- Features mathématiques pour chaque features quantitative par client : \n",
    "    - nombre\n",
    "    - moyenne\n",
    "    - maximum\n",
    "    - minimum\n",
    "    - somme"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original Memory Usage: 0.64 gb.\nNew Memory Usage: 0.29 gb.\n"
     ]
    }
   ],
   "source": [
    "# Convert types de cash\n",
    "cash = hf.convert_types(cash, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 0 columns with greater than 90% missing values.\n"
     ]
    }
   ],
   "source": [
    "# Creation de cash_by_client\n",
    "cash_by_client = hf.aggregate_client(cash, \n",
    "                                     group_vars = ['SK_ID_PREV', 'SK_ID_CURR'], \n",
    "                                     df_names = ['cash', 'client'])\n",
    "\n",
    "# Merge cash_by_client dans app_train\n",
    "app_train = app_train.merge(cash_by_client, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Suppression des colonnes missing\n",
    "app_train = hf.remove_missing_columns(app_train)"
   ]
  },
  {
   "source": [
    "___\n",
    "#### 1.6 DONNÉES CARTE DE CRÉDIT\n",
    "\n",
    "Création des features suivantes :\n",
    "- Features mathématiques pour chaque feature qualitative par client : \n",
    "    - somme\n",
    "    - nombre\n",
    "    - moyenne\n",
    "- Features mathématiques pour chaque features quantitative par client : \n",
    "    - nombre\n",
    "    - moyenne\n",
    "    - maximum\n",
    "    - minimum\n",
    "    - somme"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original Memory Usage: 0.71 gb.\nNew Memory Usage: 0.34 gb.\n"
     ]
    }
   ],
   "source": [
    "# Convert types de credit\n",
    "credit = hf.convert_types(credit, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 0 columns with greater than 90% missing values.\n"
     ]
    }
   ],
   "source": [
    "# Creation de credit_by_client\n",
    "credit_by_client = hf.aggregate_client(credit, \n",
    "                                       group_vars = ['SK_ID_PREV', 'SK_ID_CURR'], \n",
    "                                       df_names = ['credit', 'client'])\n",
    "\n",
    "# Merge credit_by_client dans app_train\n",
    "app_train = app_train.merge(credit_by_client, on=\"SK_ID_CURR\", how=\"left\")\n",
    "\n",
    "# Suppression des colonnes missing\n",
    "app_train = hf.remove_missing_columns(app_train)"
   ]
  },
  {
   "source": [
    "___\n",
    "#### 1.7 DONNÉES PAIEMENT\n",
    "\n",
    "Création des features suivantes :\n",
    "- Features mathématiques pour chaque feature qualitative par client : \n",
    "    - somme\n",
    "    - nombre\n",
    "    - moyenne\n",
    "- Features mathématiques pour chaque features quantitative par client : \n",
    "    - nombre\n",
    "    - moyenne\n",
    "    - maximum\n",
    "    - minimum\n",
    "    - somme"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original Memory Usage: 0.87 gb.\nNew Memory Usage: 0.44 gb.\n"
     ]
    }
   ],
   "source": [
    "# Convert types de installments\n",
    "installments = hf.convert_types(installments, print_info = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 0 columns with greater than 90% missing values.\n"
     ]
    }
   ],
   "source": [
    "# Creation de installments_by_clients\n",
    "installments_by_client = hf.aggregate_client(installments, \n",
    "                                             group_vars = ['SK_ID_PREV', 'SK_ID_CURR'], \n",
    "                                             df_names = ['installments', 'client'])\n",
    "\n",
    "# Merge installments_by_clietns dans app_train\n",
    "app_train = app_train.merge(installments_by_client, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Suppression des colonnes missing\n",
    "app_train = hf.remove_missing_columns(app_train)"
   ]
  },
  {
   "source": [
    "___\n",
    "### 2. TRAITEMENT DES ANOMALIES\n",
    "\n",
    "L'analyse exploratoire a fait ressortir une anomalie identique pour 18% des clients : une ancienneté au travail de 365000 jours. \n",
    "\n",
    "Nous allons remplacer cette valeur anormale par NaN, tout en conservant l'information que ces clients avaient cette anomalie.\n",
    "___"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an anomalous flag column\n",
    "app_train['DAYS_EMPLOYED_ANOM'] = app_train[\"DAYS_EMPLOYED\"] == 365243\n",
    "\n",
    "# Replace the anomalous values with nan\n",
    "app_train['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)"
   ]
  },
  {
   "source": [
    "___\n",
    "### 3. ENCODAGE DES DONNÉES\n",
    "\n",
    "Transformation des variables qualitatives en variables quantitatives via l'utilisation de :\n",
    "- label encoding pour les variables qualitatives comptant moins de 2 modalités\n",
    "- one hot encoding pour les autres variables qualitatives\n",
    "___"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3 columns were label encoded.\n"
     ]
    }
   ],
   "source": [
    "# Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "le_count = 0\n",
    "\n",
    "# Iterate through the columns\n",
    "for col in app_train:\n",
    "    if app_train[col].dtype == 'object':\n",
    "        # If 2 or fewer unique categories\n",
    "        if len(list(app_train[col].unique())) <= 2:\n",
    "            # Train on the data\n",
    "            le.fit(app_train[col])\n",
    "            # Transform data\n",
    "            app_train[col] = le.transform(app_train[col])\n",
    "            \n",
    "            # Keep track of how many columns were label encoded\n",
    "            le_count += 1\n",
    "            \n",
    "print('%d columns were label encoded.' % le_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding of categorical variables\n",
    "app_train = pd.get_dummies(app_train)"
   ]
  },
  {
   "source": [
    "___\n",
    "### 4. EXPORT DES DONNÉES\n",
    "___"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train.to_csv(\"./Resources/datasets/assembled/full_training_data.csv\", index=False, chunksize=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}